"""OWASP Top 10 for LLM Applications metadata and mappings."""

from typing import Dict, List, Optional
from dataclasses import dataclass


@dataclass
class OWASPCategory:
    """OWASP LLM security category metadata."""

    id: str
    name: str
    description: str
    full_description: str
    help_text: str
    cwe_ids: List[str]
    references: List[str]
    tags: List[str]


OWASP_LLM_CATEGORIES: Dict[str, OWASPCategory] = {
    "owasp_llm01": OWASPCategory(
        id="LLM01",
        name="Prompt Injection",
        description="Manipulating LLM via crafted inputs to override system instructions or cause unintended actions.",
        full_description=(
            "Prompt injection vulnerabilities occur when an attacker manipulates a large language model (LLM) "
            "through crafted inputs, causing the LLM to unknowingly execute the attacker's intentions. "
            "This can be done directly by 'jailbreaking' the system prompt or indirectly through manipulated "
            "external inputs, potentially leading to data exfiltration, social engineering, and other issues."
        ),
        help_text=(
            "To prevent prompt injection: (1) Enforce privilege control on LLM access to backend systems, "
            "(2) Add human approval for high-risk actions, (3) Segregate external content from user prompts, "
            "(4) Establish trust boundaries between LLM and external sources, (5) Implement input validation "
            "and sanitization, (6) Monitor and log LLM interactions for anomaly detection."
        ),
        cwe_ids=["CWE-77", "CWE-78", "CWE-94"],
        references=[
            "https://owasp.org/www-project-top-10-for-large-language-model-applications/",
            "https://llmtop10.com/llm01",
        ],
        tags=["injection", "prompt-manipulation", "jailbreak"],
    ),
    "owasp_llm02": OWASPCategory(
        id="LLM02",
        name="Sensitive Information Disclosure",
        description="LLM inadvertently reveals confidential data in responses, risking unauthorized access or privacy breaches.",
        full_description=(
            "Sensitive information disclosure occurs when LLMs inadvertently reveal confidential data, "
            "proprietary algorithms, or other sensitive details through their responses. This can result "
            "in unauthorized access to sensitive data, intellectual property, privacy violations, and other "
            "security breaches. The risk is compounded by the LLM's training data potentially containing "
            "sensitive information."
        ),
        help_text=(
            "To prevent sensitive information disclosure: (1) Integrate data sanitization and scrubbing "
            "techniques to prevent user data from entering training data, (2) Implement robust input validation "
            "and sanitization to identify and filter out potential malicious inputs, (3) Enrich the model's "
            "responses with contextual information to help users understand limitations, (4) Use techniques "
            "like federated learning or differential privacy for model training."
        ),
        cwe_ids=["CWE-200", "CWE-359", "CWE-522"],
        references=[
            "https://owasp.org/www-project-top-10-for-large-language-model-applications/",
            "https://llmtop10.com/llm02",
        ],
        tags=["data-leakage", "privacy", "confidentiality"],
    ),
    "owasp_llm03": OWASPCategory(
        id="LLM03",
        name="Supply Chain Vulnerabilities",
        description="Vulnerabilities in third-party components, training data, or models can compromise system integrity.",
        full_description=(
            "LLM supply chain vulnerabilities focus on the risks associated with the lifecycle of LLM components, "
            "including training data, models, and deployment platforms. Attackers can tamper with training data, "
            "introduce backdoors into pre-trained models, exploit vulnerable components, or compromise the "
            "infrastructure where models are hosted. This can lead to biased outputs, security breaches, or "
            "complete system failures."
        ),
        help_text=(
            "To mitigate supply chain risks: (1) Carefully vet data sources and suppliers, maintaining "
            "attestations for data provenance, (2) Use only reputable models and plugins with verified "
            "signatures, (3) Implement model and code signing, (4) Maintain an up-to-date inventory of "
            "components (SBOM), (5) Employ anomaly detection and adversarial robustness tests on models, "
            "(6) Monitor for unauthorized access to data and model repositories."
        ),
        cwe_ids=["CWE-1329", "CWE-829", "CWE-494"],
        references=[
            "https://owasp.org/www-project-top-10-for-large-language-model-applications/",
            "https://llmtop10.com/llm03",
        ],
        tags=["supply-chain", "third-party", "dependencies"],
    ),
    "owasp_llm04": OWASPCategory(
        id="LLM04",
        name="Model Denial of Service",
        description="Attackers cause resource exhaustion leading to degraded service or high costs.",
        full_description=(
            "Model Denial of Service (DoS) occurs when an attacker interacts with an LLM in a way that "
            "consumes an exceptionally high amount of resources, leading to degraded service quality for "
            "all users and increased resource costs. The vulnerability is particularly concerning for "
            "LLMs due to their resource-intensive nature and the potential for variable input lengths "
            "that can trigger complex processing."
        ),
        help_text=(
            "To prevent Model DoS: (1) Implement input validation to limit input size and complexity, "
            "(2) Set rate limiting on API requests per user/IP, (3) Implement resource monitoring and "
            "throttling, (4) Set maximum processing time for queries, (5) Design systems to handle "
            "expected load with graceful degradation, (6) Monitor for unusual resource consumption patterns."
        ),
        cwe_ids=["CWE-400", "CWE-770", "CWE-920"],
        references=[
            "https://owasp.org/www-project-top-10-for-large-language-model-applications/",
            "https://llmtop10.com/llm04",
        ],
        tags=["denial-of-service", "resource-exhaustion", "availability"],
    ),
    "owasp_llm05": OWASPCategory(
        id="LLM05",
        name="Insecure Output Handling",
        description="Inadequate validation of LLM outputs leads to injection attacks in downstream systems.",
        full_description=(
            "Insecure output handling refers to insufficient validation, sanitization, and handling of "
            "outputs generated by large language models before they are passed to other components and "
            "systems. Since LLM-generated content can be controlled by prompt input, this behavior is "
            "similar to providing users indirect access to additional functionality. This can lead to "
            "XSS, CSRF, SSRF, privilege escalation, and remote code execution in downstream systems."
        ),
        help_text=(
            "To prevent insecure output handling: (1) Treat the model as any other user and apply proper "
            "input validation on responses from the model to backend functions, (2) Follow OWASP ASVS "
            "guidelines to ensure effective input validation and sanitization, (3) Encode model output "
            "back to users to mitigate XSS and other injection attacks, (4) Use parameterized queries "
            "or prepared statements when LLM output is used in database queries or system commands."
        ),
        cwe_ids=["CWE-79", "CWE-89", "CWE-74", "CWE-94"],
        references=[
            "https://owasp.org/www-project-top-10-for-large-language-model-applications/",
            "https://llmtop10.com/llm05",
        ],
        tags=["injection", "output-validation", "xss", "sql-injection"],
    ),
    "owasp_llm06": OWASPCategory(
        id="LLM06",
        name="Insecure Plugin/Tool Use",
        description="LLM plugins/tools with inadequate access control enable unauthorized actions or data access.",
        full_description=(
            "LLM plugins and tools are extensions that enable LLMs to interact with external resources "
            "and systems. Insecure plugin design can allow attackers to craft malicious inputs that "
            "trigger unintended actions, bypass access controls, or exploit vulnerabilities in the "
            "plugin interface. This can lead to unauthorized data access, remote code execution, "
            "privilege escalation, and other security issues."
        ),
        help_text=(
            "To secure LLM plugins and tools: (1) Enforce strict parameterized input where possible, "
            "(2) Implement comprehensive input validation and sanitization, (3) Apply appropriate "
            "authentication and authorization to plugin access, (4) Implement manual user approval "
            "for high-risk actions, (5) Follow OWASP API Security Top 10 guidelines, (6) Minimize "
            "plugin functionality to only what is necessary, (7) Monitor and log plugin usage."
        ),
        cwe_ids=["CWE-285", "CWE-862", "CWE-863"],
        references=[
            "https://owasp.org/www-project-top-10-for-large-language-model-applications/",
            "https://llmtop10.com/llm06",
        ],
        tags=["plugin", "tool-use", "access-control", "authorization"],
    ),
    "owasp_llm07": OWASPCategory(
        id="LLM07",
        name="System Prompt Leakage",
        description="Attackers extract system prompts containing sensitive instructions or data.",
        full_description=(
            "System prompt leakage occurs when attackers extract the system prompts or instructions "
            "that guide an LLM's behavior. These prompts often contain sensitive information, business "
            "logic, security controls, or other confidential data. If exposed, attackers can bypass "
            "security measures, understand system limitations, or craft more effective attacks. The "
            "vulnerability is particularly concerning because system prompts form the security "
            "boundary for LLM applications."
        ),
        help_text=(
            "To prevent system prompt leakage: (1) Implement prompt injection defenses to prevent "
            "extraction attempts, (2) Avoid including sensitive information in system prompts when "
            "possible, (3) Monitor for common prompt extraction patterns, (4) Use prompt isolation "
            "techniques to separate system instructions from user inputs, (5) Implement output "
            "filtering to detect and block leaked system prompts, (6) Regularly test for prompt "
            "extraction vulnerabilities."
        ),
        cwe_ids=["CWE-200", "CWE-209", "CWE-497"],
        references=[
            "https://owasp.org/www-project-top-10-for-large-language-model-applications/",
            "https://llmtop10.com/llm07",
        ],
        tags=["information-disclosure", "prompt-leakage", "configuration"],
    ),
    "owasp_llm08": OWASPCategory(
        id="LLM08",
        name="Excessive Agency",
        description="LLM-based systems granted excessive permissions or autonomy enable unintended harmful actions.",
        full_description=(
            "Excessive agency in LLM-based systems occurs when they are granted too much autonomy, "
            "permission, or functionality, enabling them to take actions beyond their intended scope. "
            "This can happen when LLMs have access to high-privilege APIs, lack proper authorization "
            "checks, or are not constrained in the types of actions they can perform. The risk is "
            "amplified because LLMs can be manipulated through prompt injection or may hallucinate "
            "and take incorrect actions autonomously."
        ),
        help_text=(
            "To prevent excessive agency: (1) Limit plugins/tools to minimum necessary functions, "
            "(2) Implement human-in-the-loop approval for high-risk actions, (3) Apply least privilege "
            "principles to LLM plugin access, (4) Track user authorization separately from LLM agency, "
            "(5) Implement comprehensive logging and monitoring of LLM actions, (6) Set boundaries on "
            "action chains and autonomous behavior, (7) Require explicit user consent for sensitive "
            "operations."
        ),
        cwe_ids=["CWE-250", "CWE-269", "CWE-732"],
        references=[
            "https://owasp.org/www-project-top-10-for-large-language-model-applications/",
            "https://llmtop10.com/llm08",
        ],
        tags=["authorization", "privilege-escalation", "autonomy"],
    ),
    "owasp_llm09": OWASPCategory(
        id="LLM09",
        name="Overreliance",
        description="Users or systems overly depend on LLM outputs without verification, leading to misinformation or errors.",
        full_description=(
            "Overreliance on LLMs occurs when systems or users excessively depend on LLM-generated "
            "content without adequate oversight, verification, or understanding of the model's "
            "limitations. LLMs can hallucinate, generate plausible but incorrect information, produce "
            "biased content, or provide inconsistent outputs. When critical decisions are based solely "
            "on unverified LLM outputs, it can lead to misinformation, legal issues, security "
            "vulnerabilities, and reputational damage."
        ),
        help_text=(
            "To mitigate overreliance: (1) Regularly monitor and review LLM outputs with human "
            "oversight, (2) Implement cross-checking mechanisms and verification processes, "
            "(3) Use confidence scores and uncertainty indicators in LLM outputs, (4) Clearly "
            "communicate LLM limitations to users through disclaimers, (5) Provide source attribution "
            "and references for LLM-generated content, (6) Implement automated validation for "
            "fact-checkable claims, (7) Train users on LLM capabilities and limitations."
        ),
        cwe_ids=["CWE-1024", "CWE-693"],
        references=[
            "https://owasp.org/www-project-top-10-for-large-language-model-applications/",
            "https://llmtop10.com/llm09",
        ],
        tags=["hallucination", "misinformation", "verification"],
    ),
    "owasp_llm10": OWASPCategory(
        id="LLM10",
        name="Model Theft",
        description="Unauthorized access to proprietary LLM models through extraction or replication.",
        full_description=(
            "Model theft involves the unauthorized access, copying, or exfiltration of proprietary "
            "LLM models. Attackers may exploit vulnerabilities in access controls, use API queries "
            "to recreate the model, or employ side-channel attacks to extract model architecture and "
            "weights. This can lead to economic loss, competitive disadvantage, exposure of sensitive "
            "training data, and unauthorized access to model capabilities. The impact is particularly "
            "severe for organizations that invest heavily in developing custom models."
        ),
        help_text=(
            "To prevent model theft: (1) Implement strong access controls and authentication for "
            "model repositories, (2) Use encryption for models at rest and in transit, (3) Apply "
            "rate limiting and monitoring to detect extraction attempts via API, (4) Implement "
            "watermarking techniques to track model provenance, (5) Use model obfuscation when "
            "deploying to edge devices, (6) Monitor for unusual query patterns indicating model "
            "extraction, (7) Implement DRM and usage restrictions, (8) Maintain audit logs of "
            "model access."
        ),
        cwe_ids=["CWE-284", "CWE-306", "CWE-311"],
        references=[
            "https://owasp.org/www-project-top-10-for-large-language-model-applications/",
            "https://llmtop10.com/llm10",
        ],
        tags=["theft", "extraction", "intellectual-property"],
    ),
}


def get_owasp_category(marker: str) -> Optional[OWASPCategory]:
    """Get OWASP category metadata for a given marker.

    Args:
        marker: The marker name (e.g., 'owasp_llm01')

    Returns:
        OWASPCategory if found, None otherwise
    """
    return OWASP_LLM_CATEGORIES.get(marker)


def get_owasp_markers_from_test(markers: List[str]) -> List[str]:
    """Extract OWASP markers from test markers.

    Args:
        markers: List of all markers on a test

    Returns:
        List of OWASP LLM markers found
    """
    return [m for m in markers if m.startswith("owasp_llm")]


def get_cwe_tags(markers: List[str]) -> List[str]:
    """Get all CWE IDs associated with test markers.

    Args:
        markers: List of test markers

    Returns:
        List of CWE IDs
    """
    cwe_ids = []
    for marker in markers:
        category = get_owasp_category(marker)
        if category:
            cwe_ids.extend(category.cwe_ids)
    return cwe_ids


def get_security_tags(markers: List[str]) -> List[str]:
    """Get all security tags associated with test markers.

    Args:
        markers: List of test markers

    Returns:
        List of security tags
    """
    tags = []
    for marker in markers:
        category = get_owasp_category(marker)
        if category:
            tags.extend(category.tags)
    return tags
