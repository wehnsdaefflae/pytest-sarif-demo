"""Markdown report generator for pytest security test results."""

from datetime import datetime
from typing import List, Dict

from .models import TestResult
from .owasp_metadata import get_owasp_category, get_owasp_markers_from_test
from .statistics import calculate_statistics, get_test_severity


class MarkdownReportGenerator:
    """Generates Markdown reports for security test results."""

    def __init__(self, tool_name: str, tool_version: str):
        self.tool_name = tool_name
        self.tool_version = tool_version

    def generate(self, results: List[TestResult], baseline_analysis=None) -> str:
        """Generate Markdown report from test results.

        Args:
            results: List of test results
            baseline_analysis: Optional baseline regression analysis

        Returns:
            Markdown formatted report
        """
        stats = calculate_statistics(results)

        # Generate baseline section if available
        baseline_section = ""
        if baseline_analysis:
            baseline_section = self._generate_baseline_section(baseline_analysis)

        report = f"""# Security Test Report

**Tool:** {self.tool_name} v{self.tool_version}
**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

{baseline_section}

{self._generate_summary_section(stats)}

{self._generate_severity_section(stats)}

{self._generate_owasp_section(stats, results)}

{self._generate_failures_section(results)}

---

*Report generated by {self.tool_name}*
"""

        return report

    def _generate_summary_section(self, stats: Dict) -> str:
        """Generate summary statistics section."""
        pass_rate = (stats["passed"] / stats["total"] * 100) if stats["total"] > 0 else 0

        return f"""## Summary

| Metric | Count |
|--------|-------|
| Total Tests | {stats["total"]} |
| Passed | {stats["passed"]} âœ… |
| Failed | {stats["failed"]} âŒ |
| Skipped | {stats["skipped"]} â­ï¸ |
| Pass Rate | {pass_rate:.1f}% |
"""

    def _generate_severity_section(self, stats: Dict) -> str:
        """Generate severity distribution section."""
        severity_table = """## Severity Distribution

| Severity | Count | Badge |
|----------|-------|-------|
"""

        severity_order = ["critical", "high", "medium", "low", "info"]
        severity_emoji = {
            "critical": "ðŸ”´",
            "high": "ðŸŸ ",
            "medium": "ðŸŸ¡",
            "low": "ðŸ”µ",
            "info": "âšª"
        }

        for severity in severity_order:
            count = stats["severity"][severity]
            if count > 0:
                emoji = severity_emoji[severity]
                severity_table += f"| {severity.capitalize()} {emoji} | {count} | ![{severity}](https://img.shields.io/badge/{severity}-{count}-{self._get_severity_color(severity)}) |\n"

        return severity_table

    def _generate_owasp_section(self, stats: Dict, results: List[TestResult]) -> str:
        """Generate OWASP category breakdown section."""
        owasp_section = """## OWASP LLM Top 10 Coverage

| Category | Name | Total | Passed | Failed | Status |
|----------|------|-------|--------|--------|--------|
"""

        for category_id in sorted(stats["owasp_categories"].keys()):
            cat_stats = stats["owasp_categories"][category_id]
            category = get_owasp_category(f"owasp_{category_id.lower()}")

            if not category:
                continue

            status = "âœ… Pass" if cat_stats["failed"] == 0 else "âŒ Fail"

            owasp_section += (
                f"| {category.id} | {category.name} | "
                f"{cat_stats['total']} | {cat_stats['passed']} | "
                f"{cat_stats['failed']} | {status} |\n"
            )

        # Add detailed descriptions
        owasp_section += "\n### Category Details\n\n"

        for category_id in sorted(stats["owasp_categories"].keys()):
            category = get_owasp_category(f"owasp_{category_id.lower()}")

            if not category:
                continue

            cat_stats = stats["owasp_categories"][category_id]

            # Add remediation steps if there are failures
            remediation_section = ""
            if cat_stats['failed'] > 0 and category.remediation_steps:
                remediation_list = '\n'.join(f"{i}. {step}" for i, step in enumerate(category.remediation_steps, 1))
                remediation_section = f"""

**Recommended Remediation Steps:**

{remediation_list}
"""

            owasp_section += f"""#### {category.id}: {category.name}

{category.description}

**Test Results:** {cat_stats['passed']} passed, {cat_stats['failed']} failed out of {cat_stats['total']} total

**Tags:** {', '.join(f'`{tag}`' for tag in category.tags)}

**CWE IDs:** {', '.join(category.cwe_ids)}
{remediation_section}

---

"""

        return owasp_section

    def _generate_failures_section(self, results: List[TestResult]) -> str:
        """Generate failed tests section."""
        failed_results = [r for r in results if r.outcome == "failed"]

        if not failed_results:
            return """## Failed Tests

âœ… **No test failures detected!**
"""

        failures_section = f"""## Failed Tests

Found **{len(failed_results)}** failing test(s):

"""

        for i, result in enumerate(failed_results, 1):
            severity = get_test_severity(result)
            severity_emoji = {"critical": "ðŸ”´", "high": "ðŸŸ ", "medium": "ðŸŸ¡", "low": "ðŸ”µ", "info": "âšª"}.get(severity, "âšª")

            owasp_markers = get_owasp_markers_from_test(result.markers)
            owasp_info = ""
            remediation_section = ""

            if owasp_markers:
                category = get_owasp_category(owasp_markers[0])
                if category:
                    owasp_info = f"\n**OWASP Category:** {category.id} - {category.name}"

                    # Add remediation guidance
                    if category.remediation_steps:
                        top_steps = category.remediation_steps[:5]  # Show top 5 steps
                        remediation_list = '\n'.join(f"{j}. {step}" for j, step in enumerate(top_steps, 1))
                        remediation_section = f"""

**How to Fix:**

{remediation_list}
"""

            failures_section += f"""### {i}. {result.test_name}

**Severity:** {severity_emoji} {severity.upper()}
**Location:** `{result.file_path}:{result.line_number}`{owasp_info}

<details>
<summary>Error Details</summary>

```
{result.longrepr or 'No error details available'}
```

</details>
{remediation_section}

---

"""

        return failures_section


    def _get_severity_color(self, severity: str) -> str:
        """Get color code for severity badges."""
        colors = {
            "critical": "red",
            "high": "orange",
            "medium": "yellow",
            "low": "blue",
            "info": "lightgrey"
        }
        return colors.get(severity, "lightgrey")

    def _generate_baseline_section(self, baseline_analysis) -> str:
        """Generate baseline comparison section."""
        status_icon = "âš " if baseline_analysis.has_regressions else ("âœ“" if baseline_analysis.has_improvements else "â†’")

        section = f"""## Baseline Comparison {status_icon}

**Pass Rate:** {baseline_analysis.baseline_pass_rate:.1f}% â†’ {baseline_analysis.current_pass_rate:.1f}% ({baseline_analysis.pass_rate_change:+.1f}%)

| Metric | Count |
|--------|-------|
| Regressions | {baseline_analysis.regression_count} |
| Improvements | {baseline_analysis.improvement_count} |
| New Tests | {len(baseline_analysis.added_tests)} |
| Removed Tests | {len(baseline_analysis.removed_tests)} |
"""

        # Add regression details
        if baseline_analysis.has_regressions:
            section += f"\n### âš  Regressions Detected ({baseline_analysis.regression_count})\n\n"

            # Severity impact table
            if baseline_analysis.severity_impact:
                section += "**Severity Impact:**\n\n"
                section += "| Severity | Count |\n|----------|-------|\n"
                for severity, count in sorted(baseline_analysis.severity_impact.items()):
                    section += f"| {severity.upper()} | {count} |\n"
                section += "\n"

            # List regressed tests
            section += "**Regressed Tests:**\n\n"
            for test_id in baseline_analysis.regressed_tests[:10]:
                test_name = test_id.split("::")[-1]
                section += f"- `{test_name}`\n"

            if len(baseline_analysis.regressed_tests) > 10:
                section += f"\n*...and {len(baseline_analysis.regressed_tests) - 10} more*\n"

        # Add improvement details
        if baseline_analysis.has_improvements:
            section += f"\n### âœ“ Improvements ({baseline_analysis.improvement_count})\n\n"
            for test_id in baseline_analysis.fixed_tests[:5]:
                test_name = test_id.split("::")[-1]
                section += f"- `{test_name}`\n"

            if len(baseline_analysis.fixed_tests) > 5:
                section += f"\n*...and {len(baseline_analysis.fixed_tests) - 5} more*\n"

        section += "\n---\n"
        return section
